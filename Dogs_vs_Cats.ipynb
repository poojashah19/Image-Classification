{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dogs vs Cats.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cWcHfKiTGeL"
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,hi;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kagglesdsdata/competitions/3362/31148/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1618475858&Signature=LURs41GoHWC2eCuae6RfmbQb9bq8t5RLyDe9CPB2WAUX7XrfBwWQ2mZBK8si0RLJW6O2hNihGsmxYWFBrZGS4Sv4euIr2GSHA9ZXmEuPo0t3R4gxAaU5PcvXRgcCCkCVREIFBFYtJzlhLGGd8tuXwogIjgdXmkOlY2ntd1Ky9OTqLOUSagzKcQ6fOyU9%2Fbk%2BDZUyWHmOdZ4tN%2F1GuOSXeyP61vW8LE0Eo6UGJrvUMSd1m%2BU75UHzrl3HR%2F0wrnZWGltfUa1r4Tzb6GYplmVn8SQwLEY44UtEFhh2gZTuIbsQs%2FIDQ1MHhDCmGOACFpSwLYGcOlv5Yxk4JYTFbsDYsw%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.zip\" -c -O 'train.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOW3PKNDTe9I"
      },
      "source": [
        "!unzip train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GEd4WFB6Htf"
      },
      "source": [
        "##  cat=0, dog=1 because flow_from_directory numbers categories based on alphabetical order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPal2hRlYlpS"
      },
      "source": [
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "from random import random\n",
        "# create directories\n",
        "dataset_home = 'dataset_dogs_vs_cats/'\n",
        "subdirs = ['train/', 'test/']\n",
        "for subdir in subdirs:\n",
        "\t# create label subdirectories\n",
        "\tlabeldirs = ['dogs/', 'cats/']\n",
        "\tfor labldir in labeldirs:\n",
        "\t\tnewdir = dataset_home + subdir + labldir\n",
        "\t\tmakedirs(newdir, exist_ok=True)\n",
        "# seed random number generator\n",
        "seed(1)\n",
        "# define ratio of pictures to use for validation\n",
        "val_ratio = 0.20\n",
        "# copy training dataset images into subdirectories\n",
        "src_directory = 'train/'\n",
        "for file in listdir(src_directory):\n",
        "\tsrc = src_directory + '/' + file\n",
        "\tdst_dir = 'train/'\n",
        "\tif random() < val_ratio:\n",
        "\t\tdst_dir = 'test/'\n",
        "\tif file.startswith('cat'):\n",
        "\t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
        "\t\tcopyfile(src, dst)\n",
        "\telif file.startswith('dog'):\n",
        "\t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
        "\t\tcopyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtY0wdgaUHJr"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT4iPfxZUsTA"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Activation\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jBIZR_FmV1V"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XppyoO7ZUyhg"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (200, 200, 3), activation = 'relu', kernel_initializer='he_uniform'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Conv2D(64, (3, 3), activation = 'relu', kernel_initializer='he_uniform'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Conv2D(128, (3, 3), activation = 'relu', kernel_initializer='he_uniform'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yduimN7_nyWY",
        "outputId": "8fffa84d-d17b-49a4-93f2-4a85f6e10e25"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 198, 198, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 99, 99, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 97, 97, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 46, 46, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 23, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 67712)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               8667264   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 8,760,641\n",
            "Trainable params: 8,760,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyPVUhlecPyk",
        "outputId": "0efaeb9c-840f-45cb-fdd3-e000fd5af54f"
      },
      "source": [
        "data_generator = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_set = data_generator.flow_from_directory('/content/dataset_dogs_vs_cats/train/',\n",
        "                                                 target_size = (200, 200),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "val_set = data_generator.flow_from_directory('/content/dataset_dogs_vs_cats/test/',\n",
        "                                                 target_size = (200, 200),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19910 images belonging to 2 classes.\n",
            "Found 5090 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p5UB8riU5Vc",
        "outputId": "0a704d37-67d8-4479-d0a7-a784a948b8a8"
      },
      "source": [
        "classifier.fit_generator(train_set,\n",
        "                         epochs = 20,\n",
        "                         validation_data = val_set,\n",
        "                         validation_steps=len(val_set),\n",
        "                         steps_per_epoch=len(train_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "312/312 [==============================] - 75s 240ms/step - loss: 0.7372 - accuracy: 0.5296 - val_loss: 0.6617 - val_accuracy: 0.6210\n",
            "Epoch 2/20\n",
            "312/312 [==============================] - 75s 241ms/step - loss: 0.6625 - accuracy: 0.5956 - val_loss: 0.6547 - val_accuracy: 0.6128\n",
            "Epoch 3/20\n",
            "312/312 [==============================] - 74s 238ms/step - loss: 0.6516 - accuracy: 0.6091 - val_loss: 0.6263 - val_accuracy: 0.6460\n",
            "Epoch 4/20\n",
            "312/312 [==============================] - 75s 240ms/step - loss: 0.6310 - accuracy: 0.6425 - val_loss: 0.6311 - val_accuracy: 0.6269\n",
            "Epoch 5/20\n",
            "312/312 [==============================] - 74s 237ms/step - loss: 0.5965 - accuracy: 0.6752 - val_loss: 0.5634 - val_accuracy: 0.7122\n",
            "Epoch 6/20\n",
            "312/312 [==============================] - 74s 237ms/step - loss: 0.5686 - accuracy: 0.7017 - val_loss: 0.5608 - val_accuracy: 0.7045\n",
            "Epoch 7/20\n",
            "312/312 [==============================] - 74s 237ms/step - loss: 0.5542 - accuracy: 0.7191 - val_loss: 0.5298 - val_accuracy: 0.7336\n",
            "Epoch 8/20\n",
            "312/312 [==============================] - 74s 238ms/step - loss: 0.5213 - accuracy: 0.7412 - val_loss: 0.5174 - val_accuracy: 0.7444\n",
            "Epoch 9/20\n",
            "312/312 [==============================] - 74s 238ms/step - loss: 0.5061 - accuracy: 0.7531 - val_loss: 0.4923 - val_accuracy: 0.7613\n",
            "Epoch 10/20\n",
            "312/312 [==============================] - 74s 238ms/step - loss: 0.4814 - accuracy: 0.7747 - val_loss: 0.4896 - val_accuracy: 0.7570\n",
            "Epoch 11/20\n",
            "312/312 [==============================] - 74s 236ms/step - loss: 0.4604 - accuracy: 0.7881 - val_loss: 0.4672 - val_accuracy: 0.7752\n",
            "Epoch 12/20\n",
            "312/312 [==============================] - 73s 235ms/step - loss: 0.4288 - accuracy: 0.8013 - val_loss: 0.4780 - val_accuracy: 0.7694\n",
            "Epoch 13/20\n",
            "312/312 [==============================] - 73s 235ms/step - loss: 0.4183 - accuracy: 0.8139 - val_loss: 0.4539 - val_accuracy: 0.7853\n",
            "Epoch 14/20\n",
            "312/312 [==============================] - 73s 235ms/step - loss: 0.4018 - accuracy: 0.8215 - val_loss: 0.4452 - val_accuracy: 0.7892\n",
            "Epoch 15/20\n",
            "312/312 [==============================] - 73s 235ms/step - loss: 0.3747 - accuracy: 0.8326 - val_loss: 0.4492 - val_accuracy: 0.7833\n",
            "Epoch 16/20\n",
            "312/312 [==============================] - 74s 236ms/step - loss: 0.3639 - accuracy: 0.8405 - val_loss: 0.4625 - val_accuracy: 0.7817\n",
            "Epoch 17/20\n",
            "312/312 [==============================] - 73s 235ms/step - loss: 0.3399 - accuracy: 0.8534 - val_loss: 0.4354 - val_accuracy: 0.7984\n",
            "Epoch 18/20\n",
            "312/312 [==============================] - 73s 235ms/step - loss: 0.3187 - accuracy: 0.8636 - val_loss: 0.4365 - val_accuracy: 0.8014\n",
            "Epoch 19/20\n",
            "312/312 [==============================] - 73s 235ms/step - loss: 0.3071 - accuracy: 0.8681 - val_loss: 0.4623 - val_accuracy: 0.7900\n",
            "Epoch 20/20\n",
            "312/312 [==============================] - 74s 236ms/step - loss: 0.2959 - accuracy: 0.8759 - val_loss: 0.4496 - val_accuracy: 0.8022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b8344c950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg9dYzMiJX7w"
      },
      "source": [
        "classifier.save(\"model_catsVSdogs.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smvFU97tSKV-",
        "outputId": "79629c93-d779-4f18-96dd-adccd2f2f263"
      },
      "source": [
        "score = classifier.evaluate_generator(val_set, verbose=0)\n",
        "print(score[0])\n",
        "print(score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4496488869190216\n",
            "0.8021610975265503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz84PPV_11tb",
        "outputId": "b355e584-7d7c-40b6-cc9a-3a19956bf6d3"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        " \n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(200, 200))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 200, 200, 3)\n",
        "\t# center pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - [123.68, 116.779, 103.939]\n",
        "\treturn img\n",
        " \n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('/content/dog.4011.jpg')\n",
        "\t# load model\n",
        "\tmodel = load_model('/content/model_catsVSdogs.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\tprint(result[0])\n",
        " \n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp7H8T2OtxNa"
      },
      "source": [
        "# Web Application Using Flask and Flask ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP7LhlK3uBu-"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myxcXnTo2b3g"
      },
      "source": [
        "import tensorflow as tf\n",
        "from flask import Flask, render_template, request, send_from_directory\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "from tensorflow.keras import backend as K\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "app = Flask(__name__, template_folder='/content/templates/')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# dir_path = os.path.dirname(os.path.realpath(__file__))\n",
        "UPLOAD_FOLDER = '/content/uploads/'\n",
        "MODEL_FOLDER = '/content/model'\n",
        "\n",
        "def predict(filename):\n",
        "    img = load_img(filename, target_size=(200, 200))\n",
        "    img = img_to_array(img)\n",
        "    img = img.reshape(1, 200, 200, 3)\n",
        "    img = img.astype('float32')\n",
        "    img = img - [123.68, 116.779, 103.939]\n",
        "    model = load_model(MODEL_FOLDER + '/model_catsVSdogs.h5')\n",
        "    result = model.predict(img)\n",
        "    print(result)\n",
        "    result = result.flatten()\n",
        "    result = round(result[0])\n",
        "    K.clear_session()\n",
        "    return result\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "   return render_template('welcome.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST','GET'])\n",
        "def upload_file():\n",
        "\n",
        "    if request.method == 'GET':\n",
        "        return render_template('upload.html')\n",
        "    else:\n",
        "        file = request.files['filename']\n",
        "        file.save(UPLOAD_FOLDER + file.filename)\n",
        "\n",
        "        indices = {0: 'Cat', 1: 'Dog'}\n",
        "        result = predict(UPLOAD_FOLDER + file.filename)\n",
        "\n",
        "        #accuracy = round(result[0][predicted_class] * 100, 2)\n",
        "        label = indices[result]\n",
        "        print(label)\n",
        "\n",
        "    return render_template('upload.html', filename = file.filename, label = result)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}